{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq1152fnVrEQT4uW+etR5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linbinbin/Langchain_practice/blob/main/colab/Langchain_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N_CDX0RYo--"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-core\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install langchain-community\n",
        "!pip install langgraph\n",
        "!pip install langchain-graph\n",
        "!pip install langchain-anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "#os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('CLAUDE_API_KEY')\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ['LANGCHAIN_PROJECT'] = \"claude_01\"\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
        "os.environ['LANGCHAIN_ENDPOINT']=\"https://api.smith.langchain.com\"\n",
        "\n",
        "\n",
        "model = ChatAnthropic(\n",
        "    model=\"claude-3-haiku-20240307\",\n",
        "    temperature=0,\n",
        "    max_tokens=4096,\n",
        "    timeout=None,\n",
        "    max_retries=3,\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "#model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
      ],
      "metadata": {
        "id": "9zcbAid-a0i6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a347ede-2425-47b6-8b4e-32120e4f0aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"It's nice to meet you, Bob! I'm Claude, an AI assistant created by Anthropic. I'm here to help with any questions or tasks you might have. Please let me know if there's anything I can assist you with.\", response_metadata={'id': 'msg_01MYgZ2Tx9bY8YUeQTBGTeHJ', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 12, 'output_tokens': 53}}, id='run-f0bcd73c-e365-42ce-9eec-902f07dcf131-0', usage_metadata={'input_tokens': 12, 'output_tokens': 53, 'total_tokens': 65})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "config = {\"configurable\": {\"session_id\": \"chat_history_key1\"}}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "#with_message_history = RunnableWithMessageHistory(model, get_session_history)"
      ],
      "metadata": {
        "id": "Dl_17z8SAp3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hi! I'm Jim\")], \"language\": \"Japanese\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nRz95fKqM9VL",
        "outputId": "3f20bd72-5e55-42c9-c9e1-db63d7263f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'こんにちは、Jimさん。私はあなたの質問に日本語で答えさせていただきます。どのようなことでも質問してください。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"English\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "x2gtfLaNNdVp",
        "outputId": "65d70fae-f751-4678-c074-ef6448c8fc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'申し訳ありませんが、私はあなたの名前がJimさんだと理解しています。私の記憶では、最初に自己紹介の際にJimさんと仰っていただきました。私は間違っていますでしょうか?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hi! I'm job\")], \"language\": \"Chinese\"}\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qukieHUTPn1G",
        "outputId": "0d7e8b96-9609-4978-9e79-3277c403c23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你好,很高兴认识你!我是一个人工智能助手,我会尽我所能回答你的问题。请问你有什么需要帮助的吗?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}